Claro, aquí tienes un tutorial avanzado en español de España sobre la funcionalidad `Create_Tuned_Model` de Google Gemini, explicando su propósito, interacciones y ejemplos avanzados, junto con el código fuente relevante.

---

## Tutorial Avanzado de Google Gemini: `Create_Tuned_Model`

En el vasto ecosistema de la inteligencia artificial generativa, los modelos preentrenados como Gemini son increíblemente potentes, pero su verdadero potencial se desata cuando podemos especializarlos para nuestras tareas concretas. Aquí es donde entra en juego el "fine-tuning" o ajuste fino, y la función `Create_Tuned_Model` es la puerta de entrada a este proceso en la API de Gemini.

### ¿Para qué sirve `Create_Tuned_Model`?

La funcionalidad `Create_Tuned_Model` permite coger un modelo base de Google (como `gemini-1.0-pro`) y "reentrenarlo" con un conjunto de datos propio y específico. El objetivo no es enseñar al modelo desde cero, sino **especializarlo**.

Imagina que el modelo base es un genio que sabe de todo un poco. Con el "fine-tuning", lo convertimos en un experto mundial en un área muy concreta: la jerga legal de tu empresa, el estilo de escritura de tu marca, la clasificación de correos de soporte técnico o, como en el ejemplo, una tarea muy específica como generar el siguiente número en una secuencia.

Al crear un modelo ajustado, consigues:

*   **Mayor Precisión:** Para tu tarea específica, el modelo ajustado superará al modelo base.
*   **Consistencia de Estilo y Formato:** Puedes enseñarle a generar respuestas siempre en un formato determinado (por ejemplo, JSON, Markdown, o con un tono de voz específico).
*   **Reducción de la Complejidad del Prompt:** Al estar especializado, no necesitarás prompts tan largos y complejos ("prompt engineering") para guiarlo. Un prompt más simple producirá el resultado deseado.
*   **Eficiencia:** Puede que necesites menos tokens en el prompt y obtengas respuestas más concisas, optimizando costes.

### Código de Ejemplo: La Creación de un Modelo Ajustado

El siguiente código en C# muestra cómo se invoca la funcionalidad para crear un modelo que aprende a sumar 1 a cualquier número o texto numérico que se le dé.

```csharp
[Fact]
public async Task Create_Tuned_Model()
{
    // 1. Inicialización y Autenticación
    // Se necesita un AccessToken (OAuth) para operaciones de ajuste fino.
    // El ProjectId también es obligatorio.
    var googleAI = new GoogleAI(accessToken: _fixture.AccessToken);
    var model = googleAI.GenerativeModel(model: Model.GeminiPro);
    model.ProjectId = _fixture.ProjectId;

    // 2. Definición de la Solicitud de Ajuste
    var request = new CreateTunedModelRequest()
    {
        // El modelo sobre el que basaremos nuestra especialización.
        BaseModel = $"{Model.GeminiPro.SanitizeModelName()}",
        // Un nombre descriptivo para nuestro nuevo modelo.
        DisplayName = "Autogenerated Test model",
        // La tarea de ajuste define cómo se entrenará el modelo.
        TuningTask = new()
        {
            // Hiperparámetros: Ajustes técnicos del proceso de entrenamiento.
            Hyperparameters = new() 
            { 
                BatchSize = 2, 
                LearningRate = 0.001f, 
                EpochCount = 3 
            },
            // Datos de entrenamiento: El corazón del ajuste.
            TrainingData = new()
            {
                Examples = new()
                {
                    Examples = new()
                    {
                        // Pares de "entrada" -> "salida esperada"
                        new TuningExample() { TextInput = "1", Output = "2" },
                        new TuningExample() { TextInput = "3", Output = "4" },
                        new TuningExample() { TextInput = "-3", Output = "-2" },
                        new TuningExample() { TextInput = "twenty two", Output = "twenty three" },
                        new TuningExample() { TextInput = "two hundred", Output = "two hundred one" },
                        new TuningExample() { TextInput = "ninety nine", Output = "one hundred" },
                        new TuningExample() { TextInput = "8", Output = "9" },
                        new TuningExample() { TextInput = "-98", Output = "-97" },
                        new TuningExample() { TextInput = "1,000", Output = "1,001" },
                        new TuningExample() { TextInput = "thirteen", Output = "fourteen" },
                        new TuningExample() { TextInput = "seven", Output = "eight" },
                    }
                }
            }
        }
    };

    // 3. Ejecución y Lanzamiento de la Tarea
    // Esta llamada no espera a que el modelo se entrene, sino que inicia el proceso
    // y devuelve una operación de larga duración (LRO).
    var response = await model.CreateTunedModel(request);

    // 4. Verificación (en un entorno de producción, se monitorizaría el estado de la operación)
    response.Should().NotBeNull();
    response.Name.Should().NotBeNull(); // El ID de la operación
    response.Metadata.Should().NotBeNull();
    _output.WriteLine($"Name: {response.Name}");
    _output.WriteLine($"Model: {response.Metadata.TunedModel} (Steps: {response.Metadata.TotalSteps})");
}
```

### Interacciones Avanzadas con Otras Funcionalidades de Gemini

`Create_Tuned_Model` no es una función aislada. Forma parte de un ciclo de vida completo de un modelo especializado. Veamos cómo interactúa con otras funcionalidades del ecosistema Gemini en un escenario avanzado.

#### Escenario Avanzado 1: Asistente Legal Especializado en Contratos

**Objetivo:** Crear un modelo que pueda analizar cláusulas de contratos y clasificarlas según el tipo de riesgo (alto, medio, bajo) basándose en la terminología específica de nuestra empresa.

1.  **Recopilación y Preparación de Datos (`Upload_File_Using_FileAPI` y `Generate_Content`)**:
    *   Primero, subimos cientos de contratos históricos (`.pdf`, `.rtf`) a Google Cloud usando `Upload_File_Using_FileAPI`. Esto nos da un `FileUri` para cada documento.
    *   Luego, usamos `Analyze_Document_PDF_From_FileAPI` o `Analyze_Document_RTF_From_FileAPI` con un prompt que instruya a Gemini para extraer cláusulas clave y su clasificación (hecha por un humano previamente). El objetivo es generar un dataset estructurado.
    *   *Ejemplo de prompt para generar datos*: "`Dado el siguiente contrato [referencia al `FileUri`], extrae todas las cláusulas de 'Limitación de Responsabilidad' y su clasificación de riesgo asociada (que se encuentra en las notas adjuntas) y formatea la salida como un JSON con 'input' (la cláusula) y 'output' (el nivel de riesgo)`". Repetimos esto para generar cientos de ejemplos.

2.  **Ajuste del Modelo (`Create_Tuned_Model`)**:
    *   Utilizamos los datos JSON generados en el paso anterior como `TrainingData` para llamar a `Create_Tuned_Model` sobre una base como `gemini-1.5-pro`.

3.  **Gestión y Verificación (`List_Tuned_Models` y `Get_TunedModel_Information`)**:
    *   Una vez que el proceso de ajuste comienza, podemos usar `List_Tuned_Models` para ver todos nuestros modelos personalizados y su estado (CREATING, ACTIVE, FAILED).
    *   Cuando el estado es `ACTIVE`, usamos `Get_TunedModel_Information` con el ID del nuevo modelo para confirmar que está listo para usarse.

4.  **Inferencia Especializada (`Generate_Content_TunedModel`)**:
    *   Ahora, en lugar de llamar a `gemini-1.5-pro`, instanciamos el modelo con el ID de nuestro modelo ajustado (ej: `tunedModels/legal-risk-analyzer-v1`).
    *   Le pasamos una nueva cláusula de contrato con un prompt muy simple: `"Clasifica el riesgo de esta cláusula."`. El modelo, al estar especializado, sabrá exactamente qué hacer y devolverá "alto", "medio" o "bajo" con una precisión mucho mayor que el modelo base.

5.  **Mantenimiento (`Delete_Tuned_Model`)**:
    *   Cuando entrenemos una `v2` de nuestro modelo con más datos, podemos usar `Delete_Tuned_Model` para eliminar la versión antigua y evitar costes o confusiones.

---

#### Escenario Avanzado 2: Chatbot de Soporte Técnico con Conocimiento de Producto y Acceso a APIs

**Objetivo:** Crear un chatbot para una tienda de electrónica que no solo conozca a fondo los manuales de los productos, sino que también pueda consultar el stock en tiempo real.

1.  **Generación de Datos de Conversación (`Start_Chat` y `Upload_File_...`)**:
    *   Subimos los manuales de usuario en PDF con `Upload_File_Using_FileAPI`.
    *   Iniciamos una sesión de chat (`Start_Chat`) con un modelo potente como Gemini 1.5 Pro. Le damos un prompt de sistema: "`Eres un experto en crear datos de entrenamiento para chatbots. A partir del siguiente manual [referencia al `FileUri`], genera 50 pares de preguntas probables de un cliente y sus respuestas directas y concisas basadas exclusivamente en el manual.`"
    *   Almacenamos estos pares pregunta/respuesta como nuestro dataset de `TrainingData`.

2.  **Ajuste para la Conversación (`Create_Tuned_Model`)**:
    *   Ajustamos un modelo base con el dataset conversacional. Ahora tenemos un modelo que es un experto en responder preguntas sobre nuestros productos.

3.  **Integración en un Chat Funcional (`Start_Chat` con el modelo ajustado y `Function_Calling`)**:
    *   Aquí viene la magia. Iniciamos una nueva sesión de chat (`Start_Chat`) pero esta vez especificando:
        *   **El ID de nuestro modelo ajustado**.
        *   Una `Tool` con una `FunctionDeclaration` para una función que hemos definido en nuestro código, por ejemplo `get_product_stock(product_name)`.
    *   Cuando un usuario pregunta "`¿Tenéis stock del modelo X?`", el modelo ajustado, a pesar de su especialización, retiene la capacidad de `Function Calling`. Reconocerá que no puede responder desde su conocimiento (los manuales) y, en su lugar, devolverá una `FunctionCall` a `get_product_stock("modelo X")`.
    *   Nuestro código ejecuta la llamada a la API de stock real, y devuelve el resultado al chat.
    *   El modelo ajustado recibe la respuesta de la función y genera una respuesta final en lenguaje natural para el usuario: "`Sí, ¡tenemos 5 unidades del modelo X en stock!`".

Esta combinación muestra cómo el "fine-tuning" (`Create_Tuned_Model`) y el `Function Calling` pueden trabajar juntos para crear agentes de IA que son tanto **expertos en un dominio de conocimiento estático** como **capaces de interactuar con sistemas dinámicos en tiempo real**.